{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelalozano27-ship-it/machine-learning-2026-spring/blob/main/CA-02/CA02_NB_assignment_BR_ML_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCZYXwtCsL_y"
      },
      "source": [
        "#CA-02: Email Spam Classifier using Naive Bayes\n",
        "#### Completed by: Marcela and Brandon\n",
        "\n",
        "\n",
        "\n",
        "In this assignment you will ...\n",
        "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
        "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
        "\n",
        "IMPORTANT NOTE:\n",
        "\n",
        "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "#We start by importing the required libraries to be able to run the Naive Bayes model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#The sklearn package has tools for splitting the data, training the Naive Bayes model, and testing the model accuracy\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1i_g9A8aFp9",
        "outputId": "01e3a61c-94b1-4596-a240-c4f3cd990a61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount drive to allow the program to access the testing and training email data folders (The files are very large so this is the best way to read files while running the program in Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fLpnD9IZowv"
      },
      "source": [
        "#Dictionary Function\n",
        "###In this first function we will create a dictionary for the various words within the emails as we look to detect which are spam or not. To start the dictionary will collect all the words (all_words[]) in the e-mails and going line by line split the words apart and add it to the overall word list. The the Counter method will count every instance of each word.\n",
        "###The next loop in this function then helps eliminate words that are not useful. Using .isalpha() function goes through each word and if it has a number or punctutation in it then it will delete it from the record. The other criteria is if the word is equal to one (such as a, i, etc.) then it will delete those records as well.\n",
        "###Finally, the function will create a dictionary that takes the most common 3000 words to use later on for the spam detection model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_Dictionary(root_dir):\n",
        "  all_words = []\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
        "#this goes through every email and splits the words into a vocabulary list (bag of words)\n",
        "  for mail in emails:\n",
        "    with open(mail) as m:\n",
        "      for line in m:\n",
        "        words = line.split()\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words)\n",
        "  list_to_remove = list(dictionary)\n",
        "#this loop deletes the numbers, punctuations, and words that are just one letter\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False:\n",
        "      del dictionary[item]\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item]\n",
        "#the function returns the most common 3000 words\n",
        "  dictionary = dictionary.most_common(3000)\n",
        "  return dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5oLkYGwOOY2"
      },
      "source": [
        "#Extract Features Function\n",
        "###Next we will define a function called extract_features that will convert each email into a numerical feature vector using the top 3,000 words. Each email is represented as a vector of length 3,000 where each position corresponds to a word from the dictionary and the value stored is a count of each occurrence of the word. These rows of email vectors form the feature matrix which is our numerical representation of the dataset used for training the machine.\n",
        "\n",
        "###The feature matrix lets the Naive Bayes classifier calculate the probability of an email being spam or not based on the distribution of words across the different emails.\n",
        "\n",
        "###Finally the function will identify file names starting with \"spmsg\" to correctly return a 1 for spam emails and 0 for non spam emails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_features(mail_dir):\n",
        "#Collect the files\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "#Loop through each email file\n",
        "  for fil in files:\n",
        "    with open(fil) as fi:\n",
        "#Extracting words from the email text using only the third line as the body of the text.\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2:\n",
        "          words = line.split()\n",
        "#Convert each word into numerical features to build the Bag of words\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary):\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word)\n",
        "#Assign spam labels based on the filename. Files starting with spmsg will be assigned a 1 and all other files will be assigned a 0. This will form our features matrix and label vector.\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/')\n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"):\n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Instructions for using Google Colab\n",
        "1. Upload notebook and data folders to Google Drive\n",
        "2. Open notebook in Colab\n",
        "3. Mount drive and change path to your Google Drive folder"
      ],
      "metadata": {
        "id": "_6IC_E3ayq4S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "zoq-rE7Mx0pp"
      },
      "outputs": [],
      "source": [
        "#PATH to \"train_mails\" and \"test-mails\"\n",
        "TRAIN_DIR = \"/content/drive/MyDrive/CA-02/Data/train-mails\"\n",
        "TEST_DIR = \"/content/drive/MyDrive/CA-02/Data/test-mails\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "134lmhauyQxE",
        "outputId": "6f4dd9fc-42f0-4569-cbf4-14bc6943f029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n"
          ]
        }
      ],
      "source": [
        "#Create a dictionary with the previously created dictionary function using the most frequent 3,000 wordsin the training data to define feature space\n",
        "dictionary = make_Dictionary(TRAIN_DIR)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "\n",
        "#Use the extract features function with the words in the dictionary to create a feature matrix and assign each training email a 1 for spam and 0 for non spam\n",
        "train_features_matrix, train_labels = extract_features(TRAIN_DIR)\n",
        "#Extract features from test emails using the same dictionary for consistency. Spam labels are also assigned a 1 and non spam are assigned a 0 using the same labeling as the training data\n",
        "test_features_matrix, test_labels = extract_features(TEST_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxejiqgwVLQv",
        "outputId": "d89679a2-1e89-498b-b80f-253df577f102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model using Gaussian Naive Bayes algorithm...\n",
            "Training Completed\n",
            "Testing trained model to predict Test data labels\n",
            "Completed classification of the test data...now printing accuracy score by comparing the predicted labels with the test labels.\n",
            "0.9615384615384616\n"
          ]
        }
      ],
      "source": [
        "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
        "#Initialize the Naive Bayes Model we imported earlier\n",
        "model=GaussianNB()\n",
        "#Train the model using the training feature matrix and corresponding spam/not spam labels. The model learns from the patterns of word distributions for emails labeled spam vs not spam\n",
        "print(\"Training Model using Gaussian Naive Bayes algorithm...\")\n",
        "model.fit(train_features_matrix, train_labels)\n",
        "print(\"Training Completed\")\n",
        "print(\"Testing trained model to predict Test data labels\")\n",
        "#After the model is trained on the training data, it generates predictions for each email in the test dataset labeled spam or not spam.\n",
        "modelpredictions=model.predict(test_features_matrix)\n",
        "#The model accuracy is stored as a comparison of the model's predicted labels from the test data and the true labels from the test set. The accuracy gives the percentage of correctly classified emails\n",
        "modelaccuracy=accuracy_score(test_labels, modelpredictions)\n",
        "print(\"Completed classification of the test data...now printing accuracy score by comparing the predicted labels with the test labels.\")\n",
        "print(modelaccuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}